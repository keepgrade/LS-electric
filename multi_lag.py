# ================================
# ğŸ“¦ 1. ëª¨ë“ˆ ì„í¬íŠ¸
# ================================
import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor

# ================================
# ğŸ“‚ 2. ë°ì´í„° ë¡œë“œ
# ================================
train_df = pd.read_csv("data/train.csv")
test_df = pd.read_csv("data/test.csv")

# ================================
# ğŸ§¼ 3. ê³µí†µ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜
# ================================
def preprocess_datetime(df):
    df['ì¸¡ì •ì¼ì‹œ'] = pd.to_datetime(df['ì¸¡ì •ì¼ì‹œ'])
    df['ì›”'] = df['ì¸¡ì •ì¼ì‹œ'].dt.month
    df['ì¼'] = df['ì¸¡ì •ì¼ì‹œ'].dt.day
    df['ì‹œê°„'] = df['ì¸¡ì •ì¼ì‹œ'].dt.hour
    df['ìš”ì¼'] = df['ì¸¡ì •ì¼ì‹œ'].dt.weekday
    df['ì£¼ë§ì—¬ë¶€'] = df['ìš”ì¼'].apply(lambda x: 1 if x >= 5 else 0)
    df['sin_ì‹œê°„'] = np.sin(2 * np.pi * df['ì‹œê°„'] / 24)
    df['cos_ì‹œê°„'] = np.cos(2 * np.pi * df['ì‹œê°„'] / 24)
    return df

train_df = preprocess_datetime(train_df)
test_df = preprocess_datetime(test_df)

# ================================
# ğŸŒ¦ï¸ 4. ì‹œê°„ëŒ€/ê³„ì ˆë³„ ìš”ê¸ˆ ë‹¨ê°€ ê³„ì‚°
# ================================
def get_season(month):
    if month in [6, 7, 8]:
        return 'ì—¬ë¦„'
    elif month in [3, 4, 5, 9, 10]:
        return 'ë´„ê°€ì„'
    else:
        return 'ê²¨ìš¸'

def get_time_zone(hour, month):
    season = get_season(month)
    if season in ['ì—¬ë¦„', 'ë´„ê°€ì„']:
        if 22 <= hour or hour < 8:
            return 'ê²½ë¶€í•˜'
        elif (8 <= hour < 11) or (12 <= hour < 13) or (18 <= hour < 22):
            return 'ì¤‘ê°„ë¶€í•˜'
        else:
            return 'ìµœëŒ€ë¶€í•˜'
    else:
        if 22 <= hour or hour < 8:
            return 'ê²½ë¶€í•˜'
        elif (8 <= hour < 9) or (12 <= hour < 16) or (19 <= hour < 22):
            return 'ì¤‘ê°„ë¶€í•˜'
        else:
            return 'ìµœëŒ€ë¶€í•˜'

rate_table = {
    'before': {
        'ì—¬ë¦„': {'ê²½ë¶€í•˜': 93.1, 'ì¤‘ê°„ë¶€í•˜': 146.3, 'ìµœëŒ€ë¶€í•˜': 216.6},
        'ë´„ê°€ì„': {'ê²½ë¶€í•˜': 93.1, 'ì¤‘ê°„ë¶€í•˜': 115.2, 'ìµœëŒ€ë¶€í•˜': 138.9},
        'ê²¨ìš¸': {'ê²½ë¶€í•˜': 100.4, 'ì¤‘ê°„ë¶€í•˜': 146.5, 'ìµœëŒ€ë¶€í•˜': 193.4}
    },
    'after': {
        'ì—¬ë¦„': {'ê²½ë¶€í•˜': 110.0, 'ì¤‘ê°„ë¶€í•˜': 163.2, 'ìµœëŒ€ë¶€í•˜': 233.5},
        'ë´„ê°€ì„': {'ê²½ë¶€í•˜': 110.0, 'ì¤‘ê°„ë¶€í•˜': 132.1, 'ìµœëŒ€ë¶€í•˜': 155.8},
        'ê²¨ìš¸': {'ê²½ë¶€í•˜': 117.3, 'ì¤‘ê°„ë¶€í•˜': 163.4, 'ìµœëŒ€ë¶€í•˜': 210.3}
    }
}
cutoff_date = datetime(2024, 10, 24)

def apply_tariff(df):
    df['ê³„ì ˆ'] = df['ì›”'].apply(get_season)
    df['ì‹œê°„ëŒ€'] = df.apply(lambda row: get_time_zone(row['ì‹œê°„'], row['ì›”']), axis=1)
    df['ì ìš©ì‹œì '] = df['ì¸¡ì •ì¼ì‹œ'].apply(lambda x: 'before' if x < cutoff_date else 'after')
    df['ìš”ê¸ˆë‹¨ê°€'] = df.apply(lambda row: rate_table[row['ì ìš©ì‹œì ']][row['ê³„ì ˆ']][row['ì‹œê°„ëŒ€']], axis=1)
    return df

train_df = apply_tariff(train_df)
test_df = apply_tariff(test_df)

# ================================
# ğŸ”¤ 5. ì‘ì—…ìœ í˜• ì¸ì½”ë”© ë° íƒ€ê²Ÿ ì¸ì½”ë”©
# ================================
le = LabelEncoder()
train_df['ì‘ì—…ìœ í˜•_encoded'] = le.fit_transform(train_df['ì‘ì—…ìœ í˜•'])
test_df['ì‘ì—…ìœ í˜•_encoded'] = le.transform(test_df['ì‘ì—…ìœ í˜•'])

type_mean = train_df.groupby('ì‘ì—…ìœ í˜•')['ì „ê¸°ìš”ê¸ˆ(ì›)'].mean().to_dict()
train_df['ì‘ì—…ìœ í˜•_target'] = train_df['ì‘ì—…ìœ í˜•'].map(type_mean)
test_df['ì‘ì—…ìœ í˜•_target'] = test_df['ì‘ì—…ìœ í˜•'].map(type_mean)

# ================================
# ğŸ” 6. ë‹¤ì–‘í•œ í”¼ì²˜ LAG ë° ROLLING í”¼ì²˜ ìƒì„±
# ================================

# LAG ì ìš©í•  í”¼ì²˜ë“¤ ì •ì˜
lag_features = ['ì „ê¸°ìš”ê¸ˆ(ì›)', 'ìš”ê¸ˆë‹¨ê°€', 'ì‘ì—…ìœ í˜•_target', 'ì‹œê°„', 'ìš”ì¼', 'ì£¼ë§ì—¬ë¶€']
lag_periods = [1, 3, 6, 12, 24]  # 1ì‹œê°„, 3ì‹œê°„, 6ì‹œê°„, 12ì‹œê°„, 24ì‹œê°„(1ì¼) ì „

# ğŸ¯ TRAIN ë°ì´í„°ì— LAG í”¼ì²˜ ì ìš©
print("ğŸ”„ Train ë°ì´í„°ì— LAG í”¼ì²˜ ìƒì„± ì¤‘...")
for feature in lag_features:
    for lag in lag_periods:
        train_df[f'{feature}_lag_{lag}'] = train_df[feature].shift(lag)

# ğŸ¯ ROLLING í”¼ì²˜ ìƒì„± (Trainë§Œ)
rolling_features = ['ì „ê¸°ìš”ê¸ˆ(ì›)', 'ìš”ê¸ˆë‹¨ê°€', 'ì‘ì—…ìœ í˜•_target']
rolling_windows = [3, 6, 12, 24]  # 3ì‹œê°„, 6ì‹œê°„, 12ì‹œê°„, 24ì‹œê°„ ìœˆë„ìš°

print("ğŸ¯ Train ë°ì´í„°ì— ROLLING í”¼ì²˜ ìƒì„± ì¤‘...")
for feature in rolling_features:
    for window in rolling_windows:
        train_df[f'{feature}_rolling_mean_{window}'] = train_df[feature].rolling(window=window).mean()
        train_df[f'{feature}_rolling_std_{window}'] = train_df[feature].rolling(window=window).std()
        train_df[f'{feature}_rolling_max_{window}'] = train_df[feature].rolling(window=window).max()
        train_df[f'{feature}_rolling_min_{window}'] = train_df[feature].rolling(window=window).min()

# ğŸ¯ ë³€í™”ìœ¨ í”¼ì²˜ ìƒì„± (Trainë§Œ)
print("ğŸ“ˆ Train ë°ì´í„°ì— ë³€í™”ìœ¨ í”¼ì²˜ ìƒì„± ì¤‘...")
for feature in ['ì „ê¸°ìš”ê¸ˆ(ì›)', 'ìš”ê¸ˆë‹¨ê°€']:
    train_df[f'{feature}_diff_1'] = train_df[feature].diff(1)
    train_df[f'{feature}_diff_3'] = train_df[feature].diff(3)
    train_df[f'{feature}_pct_change_1'] = train_df[feature].pct_change(1)
    train_df[f'{feature}_pct_change_3'] = train_df[feature].pct_change(3)

# ê²°ì¸¡ì¹˜ ì œê±° (LAG/ROLLING í”¼ì²˜ë¡œ ì¸í•œ ê²°ì¸¡ì¹˜)
print("ğŸ§¹ ê²°ì¸¡ì¹˜ ì œê±° ì¤‘...")
train_df_clean = train_df.dropna().copy()
print(f"âœ… Train ë°ì´í„°: {len(train_df)} â†’ {len(train_df_clean)} (ê²°ì¸¡ì¹˜ ì œê±° í›„)")

# ================================
# ğŸ§ª 7. TEST ë°ì´í„°ì— LAG/ROLLING í”¼ì²˜ ì ìš©
# ================================
print("ğŸ”„ Test ë°ì´í„°ì— LAG/ROLLING í”¼ì²˜ ìƒì„± ì¤‘...")

# ë§ˆì§€ë§‰ Nê°œ ê°’ì„ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ LAG í”¼ì²˜ ìƒì„±
def create_test_lag_features(train_data, test_data, lag_features, lag_periods):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— LAG í”¼ì²˜ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    test_df_with_lag = test_data.copy()
    
    for feature in lag_features:
        if feature in train_data.columns:
            train_series = train_data[feature]
            
            for lag in lag_periods:
                if len(train_series) >= lag:
                    # ë§ˆì§€ë§‰ lag ê°œì˜ ê°’ì„ ì‚¬ìš©
                    lag_values = train_series.iloc[-lag:].values
                    
                    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸¸ì´ì— ë§ì¶° ë°˜ë³µ
                    test_length = len(test_data)
                    if test_length <= len(lag_values):
                        test_df_with_lag[f'{feature}_lag_{lag}'] = lag_values[:test_length]
                    else:
                        # ìˆœí™˜ì ìœ¼ë¡œ ê°’ í• ë‹¹
                        repeated_values = np.tile(lag_values, (test_length // len(lag_values)) + 1)
                        test_df_with_lag[f'{feature}_lag_{lag}'] = repeated_values[:test_length]
                else:
                    # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° í‰ê· ê°’ ì‚¬ìš©
                    test_df_with_lag[f'{feature}_lag_{lag}'] = train_series.mean()
    
    return test_df_with_lag

# TEST ë°ì´í„°ì— LAG í”¼ì²˜ ì ìš©
test_df = create_test_lag_features(train_df_clean, test_df, lag_features, lag_periods)

# TEST ë°ì´í„°ì— ROLLING í”¼ì²˜ ì ìš© (Train ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ê°’ë“¤ ì‚¬ìš©)
print("ğŸ¯ Test ë°ì´í„°ì— ROLLING í”¼ì²˜ ìƒì„± ì¤‘...")
for feature in rolling_features:
    if feature in train_df_clean.columns:
        train_series = train_df_clean[feature]
        
        for window in rolling_windows:
            if len(train_series) >= window:
                # ë§ˆì§€ë§‰ window ê°œì˜ ê°’ìœ¼ë¡œ í†µê³„ ê³„ì‚°
                last_values = train_series.iloc[-window:]
                test_df[f'{feature}_rolling_mean_{window}'] = last_values.mean()
                test_df[f'{feature}_rolling_std_{window}'] = last_values.std()
                test_df[f'{feature}_rolling_max_{window}'] = last_values.max()
                test_df[f'{feature}_rolling_min_{window}'] = last_values.min()
            else:
                # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ì „ì²´ í‰ê·  ì‚¬ìš©
                test_df[f'{feature}_rolling_mean_{window}'] = train_series.mean()
                test_df[f'{feature}_rolling_std_{window}'] = train_series.std()
                test_df[f'{feature}_rolling_max_{window}'] = train_series.max()
                test_df[f'{feature}_rolling_min_{window}'] = train_series.min()

# TEST ë°ì´í„°ì— ë³€í™”ìœ¨ í”¼ì²˜ ì ìš©
print("ğŸ“ˆ Test ë°ì´í„°ì— ë³€í™”ìœ¨ í”¼ì²˜ ìƒì„± ì¤‘...")
for feature in ['ì „ê¸°ìš”ê¸ˆ(ì›)', 'ìš”ê¸ˆë‹¨ê°€']:
    if feature in train_df_clean.columns:
        train_series = train_df_clean[feature]
        
        # ë§ˆì§€ë§‰ ê°’ê³¼ ê·¸ ì´ì „ ê°’ë“¤ì˜ ì°¨ì´ ê³„ì‚°
        if len(train_series) >= 2:
            test_df[f'{feature}_diff_1'] = train_series.iloc[-1] - train_series.iloc[-2]
        if len(train_series) >= 4:
            test_df[f'{feature}_diff_3'] = train_series.iloc[-1] - train_series.iloc[-4]
        if len(train_series) >= 2:
            test_df[f'{feature}_pct_change_1'] = (train_series.iloc[-1] - train_series.iloc[-2]) / train_series.iloc[-2]
        if len(train_series) >= 4:
            test_df[f'{feature}_pct_change_3'] = (train_series.iloc[-1] - train_series.iloc[-4]) / train_series.iloc[-4]

# ================================
# ğŸ§  8. í”¼ì²˜ ì„ íƒ ë° ëª¨ë¸ í•™ìŠµ
# ================================

# ì‚¬ìš©í•  í”¼ì²˜ë“¤ ì •ì˜
base_features = [
    'ì‘ì—…ìœ í˜•_encoded', 'ì‘ì—…ìœ í˜•_target',
    'ì›”', 'ì¼', 'ìš”ì¼', 'ì£¼ë§ì—¬ë¶€',
    'sin_ì‹œê°„', 'cos_ì‹œê°„', 'ìš”ê¸ˆë‹¨ê°€'
]

# LAG í”¼ì²˜ë“¤
lag_feature_names = []
for feature in lag_features:
    if feature != 'ì „ê¸°ìš”ê¸ˆ(ì›)':  # íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ì œì™¸
        for lag in lag_periods:
            lag_feature_names.append(f'{feature}_lag_{lag}')

# ROLLING í”¼ì²˜ë“¤
rolling_feature_names = []
for feature in rolling_features:
    if feature != 'ì „ê¸°ìš”ê¸ˆ(ì›)':  # íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ì œì™¸
        for window in rolling_windows:
            rolling_feature_names.extend([
                f'{feature}_rolling_mean_{window}',
                f'{feature}_rolling_std_{window}',
                f'{feature}_rolling_max_{window}',
                f'{feature}_rolling_min_{window}'
            ])

# ë³€í™”ìœ¨ í”¼ì²˜ë“¤
diff_feature_names = []
for feature in ['ìš”ê¸ˆë‹¨ê°€']:  # ì „ê¸°ìš”ê¸ˆì€ íƒ€ê²Ÿì´ë¯€ë¡œ ì œì™¸
    diff_feature_names.extend([
        f'{feature}_diff_1', f'{feature}_diff_3',
        f'{feature}_pct_change_1', f'{feature}_pct_change_3'
    ])

# ì „ì²´ í”¼ì²˜ ë¦¬ìŠ¤íŠ¸
all_features = base_features + lag_feature_names + rolling_feature_names + diff_feature_names

# ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í”¼ì²˜ë§Œ ì„ íƒ
available_features = [f for f in all_features if f in train_df_clean.columns and f in test_df.columns]

print(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ ìˆ˜: {len(available_features)}")
print(f"ğŸ¯ ê¸°ë³¸ í”¼ì²˜: {len(base_features)}")
print(f"ğŸ”„ LAG í”¼ì²˜: {len([f for f in lag_feature_names if f in available_features])}")
print(f"ğŸ¯ ROLLING í”¼ì²˜: {len([f for f in rolling_feature_names if f in available_features])}")
print(f"ğŸ“ˆ ë³€í™”ìœ¨ í”¼ì²˜: {len([f for f in diff_feature_names if f in available_features])}")

target = 'ì „ê¸°ìš”ê¸ˆ(ì›)'

# ë°ì´í„° ì¤€ë¹„
X = train_df_clean[available_features]
y = train_df_clean[target]
X_test = test_df[available_features]

# ê²°ì¸¡ì¹˜ í™•ì¸ ë° ì²˜ë¦¬
print(f"ğŸ” Train ê²°ì¸¡ì¹˜: {X.isna().sum().sum()}")
print(f"ğŸ” Test ê²°ì¸¡ì¹˜: {X_test.isna().sum().sum()}")

# ê²°ì¸¡ì¹˜ê°€ ìˆë‹¤ë©´ 0ìœ¼ë¡œ ì±„ìš°ê¸°
X = X.fillna(0)
X_test = X_test.fillna(0)

# Train/Validation ë¶„í• 
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# ëª¨ë¸ í•™ìŠµ
print("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
model = XGBRegressor(
    n_estimators=500,
    max_depth=6,
    learning_rate=0.03,
    subsample=0.8,
    colsample_bytree=0.8,
    reg_alpha=0.1,
    reg_lambda=0.1,
    random_state=42,
    n_jobs=-1
)

model.fit(X_train, y_train)

# ================================
# ğŸ“Š 9. ì„±ëŠ¥ í‰ê°€
# ================================
val_pred = model.predict(X_val)
mae = mean_absolute_error(y_val, val_pred)
rmse = np.sqrt(mean_squared_error(y_val, val_pred))
r2 = r2_score(y_val, val_pred)

print("\n" + "="*50)
print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
print("="*50)
print(f"âœ… MAE: {mae:.2f}")
print(f"ğŸ“‰ RMSE: {rmse:.2f}")
print(f"ğŸ“Š RÂ² Score: {r2:.4f}")

# í”¼ì²˜ ì¤‘ìš”ë„ ìƒìœ„ 20ê°œ ì¶œë ¥
feature_importance = pd.DataFrame({
    'feature': available_features,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nğŸ† ìƒìœ„ 20ê°œ ì¤‘ìš” í”¼ì²˜:")
print(feature_importance.head(20).to_string(index=False))

# ================================
# ğŸ“ 10. ê²°ê³¼ ì €ì¥
# ================================
print("\nğŸ”® ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± ì¤‘...")
test_predictions = model.predict(X_test)
test_df['ì „ê¸°ìš”ê¸ˆ(ì›)'] = test_predictions

submission = test_df[['id', 'ì „ê¸°ìš”ê¸ˆ(ì›)']]
submission.to_csv("submission_multi_lag.csv", index=False)

print("="*50)
print("ğŸ“ submission_multi_lag.csv ì €ì¥ ì™„ë£Œ")
print(f"ğŸ“ˆ ì˜ˆì¸¡ ë²”ìœ„: {test_predictions.min():.2f} ~ {test_predictions.max():.2f}")
print(f"ğŸ“Š ì˜ˆì¸¡ í‰ê· : {test_predictions.mean():.2f}")
print("="*50)